{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 59,
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "# Only need to run this one time to get python-docx and openpyxl installed in the Env\n",
    "# !pip install python-docx\n",
    "# !pip install pandas openpyxl"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "metadata": {},
   "outputs": [],
   "source": [
    "## Lego superpowers engaged\n",
    "from docx import Document\n",
    "import pandas as pd\n",
    "import os\n",
    "import re"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 36,
   "metadata": {},
   "outputs": [],
   "source": [
    "## Identify a table with just links so we can throw it away\n",
    "def is_links_table(table):\n",
    "    # Check if the table is a 1x1 table and contains URLs\n",
    "    if len(table.rows) == 1 and len(table.rows[0].cells) == 1:\n",
    "        cell_text = table.rows[0].cells[0].text\n",
    "        # Check for URL patterns or additional information text\n",
    "        if re.search(r'https?://', cell_text) or re.search(r'additional information', cell_text):\n",
    "            return True\n",
    "    return False\n",
    "\n",
    "## Extract all of the tables into dataFrames - return a list of dataFrames\n",
    "def extract_tables_from_docx(docx_path):\n",
    "    doc = Document(docx_path)\n",
    "    tables_list = []\n",
    "    for table in doc.tables:\n",
    "        if is_links_table(table):\n",
    "            continue  # Skip this table\n",
    "        \n",
    "        data = [[cell.text for cell in row.cells] for row in table.rows]\n",
    "        df_table = pd.DataFrame(data[1:], columns=data[0])  # Use the first row as column headers\n",
    "        tables_list.append(df_table)\n",
    "    return tables_list\n",
    "\n",
    "def process_folder(folder_path):\n",
    "    all_tables = []\n",
    "    for filename in os.listdir(folder_path):\n",
    "        if filename.endswith(\".docx\"):\n",
    "            docx_path = os.path.join(folder_path, filename)\n",
    "            tables = extract_tables_from_docx(docx_path)\n",
    "            # Add a column to each table indicating the filename\n",
    "            for table in tables:\n",
    "                table['Source File'] = filename  # Add filename as a column\n",
    "            all_tables.extend(tables)\n",
    "    return all_tables\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 37,
   "metadata": {},
   "outputs": [],
   "source": [
    "# ## Define where our first document lives\n",
    "# docx_path = r'unusnldwp2sampledata\\LIBERIA.docx'\n",
    "\n",
    "## Define the folder where all documents live\n",
    "folder_path = r'unusnldwp2sampledata'"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 55,
   "metadata": {},
   "outputs": [],
   "source": [
    "# ## Test extraction with just one file\n",
    "# tables = extract_tables_from_docx(docx_path)\n",
    "# tables[0].head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 40,
   "metadata": {},
   "outputs": [],
   "source": [
    "all_tables = process_folder(folder_path)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 57,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>Country</th>\n",
       "      <th>Explanatory notes</th>\n",
       "      <th>Example: LIBERIA</th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th>Source File</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>Main event</td>\n",
       "      <td>Modulating event that produces one or more haz...</td>\n",
       "      <td>Heavy Rainfall, SLR/Coastal Flooding in Montse...</td>\n",
       "      <td></td>\n",
       "      <td></td>\n",
       "      <td></td>\n",
       "      <td></td>\n",
       "      <td>LIBERIA.docx</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>Hazard</td>\n",
       "      <td>Single hazardous event causing loss and damage</td>\n",
       "      <td>Floods resulting from heavy Rainfall in margib...</td>\n",
       "      <td></td>\n",
       "      <td></td>\n",
       "      <td></td>\n",
       "      <td></td>\n",
       "      <td>LIBERIA.docx</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>Description &amp; context</td>\n",
       "      <td>Describe the event and its context</td>\n",
       "      <td>In recent years, climate change related coasta...</td>\n",
       "      <td></td>\n",
       "      <td></td>\n",
       "      <td></td>\n",
       "      <td></td>\n",
       "      <td>LIBERIA.docx</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td></td>\n",
       "      <td></td>\n",
       "      <td></td>\n",
       "      <td></td>\n",
       "      <td>Needs</td>\n",
       "      <td>Sources of support</td>\n",
       "      <td>Gaps</td>\n",
       "      <td>LIBERIA.docx</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>1. Anticipatory Arrangement (Pre-Phase 1: befo...</td>\n",
       "      <td>Anticipatory arrangements are those that trigg...</td>\n",
       "      <td>Flood mapping has been done to identify hotspo...</td>\n",
       "      <td></td>\n",
       "      <td></td>\n",
       "      <td></td>\n",
       "      <td></td>\n",
       "      <td>LIBERIA.docx</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "                                             Country  \\\n",
       "0                                         Main event   \n",
       "1                                             Hazard   \n",
       "2                              Description & context   \n",
       "3                                                      \n",
       "4  1. Anticipatory Arrangement (Pre-Phase 1: befo...   \n",
       "\n",
       "                                   Explanatory notes  \\\n",
       "0  Modulating event that produces one or more haz...   \n",
       "1     Single hazardous event causing loss and damage   \n",
       "2                 Describe the event and its context   \n",
       "3                                                      \n",
       "4  Anticipatory arrangements are those that trigg...   \n",
       "\n",
       "                                    Example: LIBERIA           \\\n",
       "0  Heavy Rainfall, SLR/Coastal Flooding in Montse...            \n",
       "1  Floods resulting from heavy Rainfall in margib...            \n",
       "2  In recent years, climate change related coasta...            \n",
       "3                                                       Needs   \n",
       "4  Flood mapping has been done to identify hotspo...            \n",
       "\n",
       "                              Source File  \n",
       "0                            LIBERIA.docx  \n",
       "1                            LIBERIA.docx  \n",
       "2                            LIBERIA.docx  \n",
       "3  Sources of support  Gaps  LIBERIA.docx  \n",
       "4                            LIBERIA.docx  "
      ]
     },
     "execution_count": 57,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "all_tables[1].head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 66,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "All DataFrames have been saved to Excel files in the 'processeddata' folder.\n"
     ]
    }
   ],
   "source": [
    "output_folder_path = 'unusnldwp2sampledata/processedData'\n",
    "\n",
    "# Loop through each DataFrame in the list\n",
    "for dataframe in all_tables:\n",
    "    original_filename = dataframe['Source File'].iloc[0]  # Access the first item for the filename\n",
    "    # Remove any file extension from the original_filename\n",
    "    original_filename_without_extension = os.path.splitext(original_filename)[0]\n",
    "    # Construct the new filename by adding '_tables' suffix and the .xlsx extension\n",
    "    new_filename = f\"{original_filename_without_extension}_tables.xlsx\"\n",
    "    # Create the full path to the new file\n",
    "    full_path = os.path.join(output_folder_path, new_filename)\n",
    "    \n",
    "    # Save the dataframe to an Excel file in the specified folder, excluding the index\n",
    "    dataframe.to_excel(full_path, index=False)  # Add `columns=[col for col in dataframe.columns if col != 'originalFileName']` to exclude the filename column\n",
    "\n",
    "print(\"All DataFrames have been saved to Excel files in the 'processeddata' folder.\")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 64,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "list"
      ]
     },
     "execution_count": 64,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "UNSurvey",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.7"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
